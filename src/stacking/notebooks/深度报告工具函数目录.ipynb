{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coding=utf-8\n",
    "\n",
    "############################################################################################\n",
    "# ---------------------深度报告工具函数目录---------------------------\n",
    "# 1. 数据IO\n",
    "#    get_data_items(universe_list, date_list, factor_list, [adj, thread_count, use_datacube])  取优矿中的因子库因子数据\n",
    "#    add_indu_col(dframe, [indu_name])                                                         获取行业分类:在dataframe后增加一列，表示对应的申万行业分类\n",
    "#    stock_special_tag(start_date, end_date, [halt, st, pre_new, pre_new_length])              获取个股标签信息(停牌,ST,次新股)：某一时间区间内，根据股票的是否满足某些条件，打上标签\n",
    "\n",
    "# 2. 信号处理\n",
    "#    zscore_by_indu(dframe, col_list, [indu_name])                                             各个因子在行业内进行标准化(ZSCORE)\n",
    "#    fillna_indu_median(dframe, col_list, [indu_name])                                         用行业内中位数填充因子空值\n",
    "#    netralize_dframe(dframe, col_list, [exclude_style])                                       批量因子中性化处理:对风险模型的风格因子和行业因子进行中性化\n",
    "#    mad_winsorize(dframe, col_list, [sigma_n])                                                因子去极值处理: 绝对中位数差去极值\n",
    "#    fin_data_pit2cont(pit_data_frame, sdate, edate)                                           将PIT数据转成时间连续数据  \n",
    "#    signal_grouping(signal_df, factor_name, ngrp)                                             因子分组， 每天根据因子值将股票进行等分\n",
    "\n",
    "\n",
    "# 3. 信号分析\n",
    "#    calc_ic(factor_df, return_df, factor_list, [return_col_name, ic_type])                    给定factor_df， return_df，计算对于的IC\n",
    "#    monthly_factor_ic(factor_df, factor_list, [start_date, end_date, ic_type, month_len])\t   输入因子的dataframe，计算月度因子的IC序列（未来1个月，n个月，可自定义）\n",
    "\n",
    "# 4. 信号合成\n",
    "#    multifactor_icir_comb(factor_df, factor_list, window, [ic_type, month_len,...])           根据过去N期的IC_IR，得到因子的权重和加权得到的因子值\n",
    "\n",
    "# 5. 组合回测\n",
    "#    get_performance(bt, [excess])\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t   根据优矿的回测结果（或者类似的回测数据）计算净值和回撤\n",
    "#    long_short_backtest(signal_df, return_df, factor_name, return_name, [direction])          简易回测（不考虑停牌、涨跌停无法交易）：因子多组合回测/纯多头组合回测\n",
    "#    easy_backtest(signal_df, return_df, factor_name, return_name, return_name, [method,...])  简易因子回测组合， 根据因子值将个股等分成n组，指定回测方式，可进行多空回测或纯多头回测。\n",
    "#    simple_group_backtest(signal_df, return_df, factor_name, return_name, [ngrp])             对因子进行简单的分组多头回测。返回各组收益率和累计收益率， 编号越大，因子值越大。\n",
    "\n",
    "\n",
    "############################################################################################\n",
    "\n",
    "from multiprocessing.dummy import Pool as ThreadPool\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from quartz_extensions import neutralize, standardize, winsorize\n",
    "import gevent\n",
    "\n",
    "\n",
    "############################################################################################\n",
    "# Usage: get_data_items(set_universe(\"A\"), ['20070101', '20080104'], ['LCAP', 'PE'])\n",
    "############################################################################################\n",
    "# 取优矿中的因子库因子数据\n",
    "def get_data_items(universe_list, date_list, factor_list, adj=None, thread_count=16, use_datacube=False):\n",
    "    '''\n",
    "    universe_list: ['000001.XSHE', '600036.XSHG', ...]\n",
    "    date_list:数据日期列表，[\"2007001\", \"20180706\", '...']\n",
    "    factor_list: 要取的数据列表(data_cube支持的)\n",
    "    adj: 数据复权方式（比如取closeprice时）， None/pre\n",
    "    thread_count: 取数据的线程数，默认16个\n",
    "    返回:\n",
    "        frame_list:[frame_t0, frame_t1, ...frame_tn], frame_tn为tn日对应的因子dataframe\n",
    "        frame_tn的列为: ticker, tradeDate, factor_list, tradeDate格式为\"%Y%m%d\"\n",
    "    '''\n",
    "\n",
    "    t_start = time.time()\n",
    "    pool = ThreadPool(processes=16)\n",
    "\n",
    "    # 获取给定日期的因子信息\n",
    "    def get_factor_by_day(parms):\n",
    "        '''\n",
    "        参数：\n",
    "            params = [my_universe, tdate, data_item_list]\n",
    "            my_universe: secID的列表\n",
    "            tdate: 时间， %Y%m%d\n",
    "            data_item_list: 要取的数据列表\n",
    "        返回:\n",
    "            DataFrame, 返回给定日期的因子值\n",
    "        '''\n",
    "\n",
    "        tdate, data_item_list, my_universe = parms\n",
    "\n",
    "        cnt = 0\n",
    "        while True:\n",
    "            try:\n",
    "                if use_datacube:\n",
    "                    data = get_data_cube(my_universe, ['ticker'] + data_item_list, tdate, tdate,\n",
    "                                         style='ast', adj=adj)\n",
    "                    data = data.to_frame().reset_index()\n",
    "                    data = data[['ticker', 'major'] + data_item_list]\n",
    "                    data.rename(columns={'major': 'tradeDate'}, inplace=True)\n",
    "                    tmp_frame = data.copy()\n",
    "                else:\n",
    "                    tmp_frame = DataAPI.MktStockFactorsOneDayProGet(tradeDate=tdate, secID=u\"\", ticker=u\"\",\n",
    "                                                                    field=['ticker', 'tradeDate'] + data_item_list,\n",
    "                                                                    pandas=\"1\")\n",
    "                tmp_frame['tradeDate'] = tdate.replace(\"-\", \"\")\n",
    "                return tmp_frame\n",
    "\n",
    "            except Exception as e:\n",
    "                cnt += 1\n",
    "                print \"get data failed in get_factors, reason:%s, retry again, retry count:%s\" % (e, cnt)\n",
    "                if cnt >= 3:\n",
    "                    print \"max get data retry, will exit\"\n",
    "                    raise Exception(e)\n",
    "            return\n",
    "\n",
    "    pool_args = zip(date_list, [factor_list] * len(date_list), [universe_list] * len(date_list))\n",
    "    frame_list = pool.map(get_factor_by_day, pool_args)\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "    t_end = time.time()\n",
    "    print \"[quant_util.get_data_items] finished!, time cost:%s\" % (t_end - t_start)\n",
    "    return frame_list\n",
    "\n",
    "\n",
    "############################################################################################\n",
    "# Usage: add_indu_col(factor_frame, indu_name='industryName1')\n",
    "############################################################################################\n",
    "# 在dataframe后增加一列，表示对应的申万行业分类\n",
    "def add_indu_col(dframe, indu_name='industryName1'):\n",
    "    '''\n",
    "    dframe: panel/横截面/时间序列数据，至少包含[ticker, tradeDate]列， tradeDate为\"%Y%m%d\"格式\n",
    "    返回：\n",
    "          dframe，增加一列，标识对应的申万行业分类\n",
    "    '''\n",
    "    dframe = dframe.copy()\n",
    "    # 先拿到申万一级行业的分类\n",
    "    sw_frame = DataAPI.EquIndustryGet(ticker=np.unique(dframe.ticker.values), industryVersionCD=u\"010303\",\n",
    "                                      field=[\"ticker\", indu_name, 'intoDate'], pandas=\"1\")\n",
    "    sw_frame['tradeDate'] = sw_frame['intoDate'].apply(lambda x: x.replace(\"-\", \"\"))\n",
    "\n",
    "    # 标志dframe原有的行\n",
    "    dframe['original_row'] = 1\n",
    "\n",
    "    # 合并行业分类\n",
    "    dframe = dframe.merge(sw_frame[['ticker', 'tradeDate', indu_name]], on=['ticker', 'tradeDate'], how='outer')\n",
    "    # 排序后，按股票的历史上行业分类进行前向填充\n",
    "    dframe.sort_values(by=['ticker', 'tradeDate'], ascending=[True, True], inplace=True)\n",
    "    dframe[indu_name] = dframe.groupby(['ticker']).apply(lambda x: x[indu_name].fillna(method='ffill')).values\n",
    "\n",
    "    # 删除非dframe原有的行，保证输入输出的日期是一样的\n",
    "    dframe.dropna(subset=['original_row'], inplace=True)\n",
    "    del dframe['original_row']\n",
    "    return dframe\n",
    "\n",
    "\n",
    "############################################################################################\n",
    "# Usage: zscore_by_indu(factor_frame,['LCAP', 'PE'])\n",
    "############################################################################################\n",
    "# 各个因子在行业内进行标准化(ZSCORE)\n",
    "def zscore_by_indu(dframe, col_list, indu_name='industryName1'):\n",
    "    '''\n",
    "    dframe: panel/横截面/时间序列数据, 列至少包括: ['ticker','tradeDate', col_list], tradeDate为 \"%Y%m%d\"\n",
    "    col_list: 需要进行中性化的因子列表\n",
    "    返回：\n",
    "         dframe，和输入dframe相比，多了indu_name一列\n",
    "    '''\n",
    "    # 得到对应的行业分类\n",
    "    dframe = add_indu_col(dframe, indu_name=indu_name)\n",
    "\n",
    "    # 对df的col_list每一列进行zscore标准化\n",
    "    def zscore_frame(df, col_list):\n",
    "        df[col_list] = (df[col_list] - df[col_list].mean()) / df[col_list].std()\n",
    "        return df\n",
    "\n",
    "    # 按行业进行ZSCORE\n",
    "    dframe = dframe.groupby(['tradeDate', indu_name]).apply(zscore_frame, col_list)\n",
    "    return dframe\n",
    "\n",
    "\n",
    "############################################################################################\n",
    "# Usage: fillna_indu_median(factor_frame,['LCAP', 'PE'])\n",
    "############################################################################################\n",
    "# 用行业内中位数填充因子空值\n",
    "def fillna_indu_median(dframe, col_list, indu_name='industryName1'):\n",
    "    '''\n",
    "    dframe: panel/横截面/时间序列数据, 至少包含 ['ticker', 'tradeDate', col_list], tradeDate为\"%Y%m%d\"\n",
    "    col_list: 需要进行中性化的因子列表\n",
    "    返回：\n",
    "        经过空值填充的dframe\n",
    "    '''\n",
    "    if indu_name not in dframe.columns:\n",
    "        dframe = add_indu_col(dframe, indu_name=indu_name)\n",
    "\n",
    "    # 中位数填充空值\n",
    "    def fill_na_media(df, col):\n",
    "        df[col] = df[col].fillna(df[col].median())\n",
    "        return df\n",
    "\n",
    "    dframe = dframe.groupby(['tradeDate', indu_name]).apply(fill_na_media, col_list)\n",
    "    return dframe\n",
    "\n",
    "\n",
    "############################################################################################\n",
    "# Usage: netralize_dframe(factor_frame,['LCAP', 'PE'], exclude_stype=['BETA', 'SIZE', 'Bank'])\n",
    "############################################################################################\n",
    "def netralize_dframe(dframe, col_list, exclude_style=[]):\n",
    "    '''\n",
    "    dframe: panel/横截面/时间序列数据, 列至少包括['ticker', 'tradeDate', col_list]\n",
    "    col_list: 需要进行中性化的因子列表\n",
    "    exclude_style: 不进行中性的风格\n",
    "    返回：\n",
    "         经过中性化后的dframe\n",
    "    '''\n",
    "\n",
    "    # 在某一天对col_list的每一个因子进行中性化\n",
    "    def neutralize_by_date(params):\n",
    "        '''\n",
    "        params=[dframe_by_tdate, col_list, exclude_style]\n",
    "        dframe_by_tdate: tdate日的dframe，列至少包括['ticker', 'tradeDate', col_list]\n",
    "        exclude_style: 不进行中性化的风格, list\n",
    "        '''\n",
    "        dframe_by_tdate, col_list, exclude_style = params\n",
    "        tdate = dframe_by_tdate.tradeDate.values[0]\n",
    "        # 对每个因子进行中性化\n",
    "        for col in col_list:\n",
    "            if len(dframe_by_tdate[col].dropna()) < 11:\n",
    "                # print \"Netralize skipped for %s, %s because  too many nan factor values\" %(col, tdate)\n",
    "                continue\n",
    "            dframe_by_tdate[col] = neutralize(dframe_by_tdate[col], target_date=tdate, exclude_style_list=exclude_style)\n",
    "        return dframe_by_tdate\n",
    "\n",
    "    dframe = dframe.set_index('ticker')\n",
    "    # 将dframe拆成list，便于利用协程加快计算\n",
    "    col_lists = []\n",
    "    frame_list = []\n",
    "    exclude_lists = []\n",
    "    for tdate, tdframe in dframe.groupby(['tradeDate']):\n",
    "        col_lists.append(col_list)\n",
    "        frame_list.append(tdframe)\n",
    "        exclude_lists.append(exclude_style)\n",
    "    # 利用协程进行计算\n",
    "    jobs = [gevent.spawn(neutralize_by_date, value) for value in zip(frame_list, col_lists, exclude_lists)]\n",
    "    gevent.joinall(jobs)\n",
    "    new_frame_list = [result.value for result in jobs]\n",
    "    dframe = pd.concat(new_frame_list, axis=0)\n",
    "    dframe.reset_index(inplace=True)\n",
    "    return dframe\n",
    "\n",
    "\n",
    "############################################################################################\n",
    "# Usage: netralize_dframe(factor_frame,['LCAP', 'PE'], sigma_n=3)\n",
    "############################################################################################\n",
    "# 绝对中位数差法\n",
    "def mad_winsorize(dframe, col_list, sigma_n=3):\n",
    "    '''\n",
    "    dframe: panel/横截面/时间序列数据, 列至少包括: ['ticker','tradeDate', col_list], tradeDate为 \"%Y%m%d\"\n",
    "    col_list: 需要进行winsorize的因子列表\n",
    "    '''\n",
    "\n",
    "    def mad_winsor_by_day(dframe_tdate, col_list, sigma_n):\n",
    "        '''\n",
    "        按照[dm+sigma_n*dm1, dm-sigma_n*dm1]进行winsorize\n",
    "        dm: median\n",
    "        dm1: median(abs(origin_data - median)), 即 MAD值\n",
    "        参数:\n",
    "            dframe_tdate: 某一期的多个因子值的dataframe\n",
    "        返回:\n",
    "            去极值后的dframe_tdate\n",
    "        '''\n",
    "        dm = dframe_tdate[col_list].median()\n",
    "        dm1 = (dframe_tdate[col_list] - dm).abs().median()\n",
    "\n",
    "        upper = dm + sigma_n * dm1\n",
    "        lower = dm - sigma_n * dm1\n",
    "        for col in col_list:\n",
    "            tmp_col = dframe_tdate[col]\n",
    "            tmp_col[tmp_col > upper[col]] = upper[col]\n",
    "            tmp_col[tmp_col < lower[col]] = lower[col]\n",
    "            dframe_tdate[col] = tmp_col\n",
    "        return dframe_tdate\n",
    "\n",
    "    dframe = dframe.groupby(['tradeDate']).apply(mad_winsor_by_day, col_list, sigma_n)\n",
    "    return dframe\n",
    "\n",
    "\n",
    "############################################################################################\n",
    "# Usage: calc_ic(factor_frame, return_df, ['LCAP', 'PE'], ic_type='spearman')\n",
    "############################################################################################\n",
    "# 给定factor_df， return_df，计算对于的IC\n",
    "def calc_ic(factor_df, return_df, factor_list, return_col_name='target_return', ic_type='spearman'):\n",
    "    \"\"\"\n",
    "    计算因子IC值, 本月和下月因子值的秩相关\n",
    "    params:\n",
    "            factor_df: DataFrame, columns=['ticker', 'tradeDate', factor_list]\n",
    "            return_df: DataFrame, colunms=['ticker, 'tradeDate'， return_col_name], 预先计算好的未来的收益率\n",
    "            factor_list:　list， 需要计算IC的因子名list\n",
    "            return_col_name: str, return_df中的收益率列名\n",
    "            method: : {'spearman', 'pearson'}, 默认'spearman', 指定计算rank IC('spearman')或者Normal IC('pearson')\n",
    "    return:\n",
    "            DataFrame, 返回各因子的IC序列， 列为: ['tradeDate', factor_list]\n",
    "    \"\"\"\n",
    "    merge_df = factor_df.merge(return_df, on=['ticker', 'tradeDate'])\n",
    "    # 遍历每个因子，计算对应的IC\n",
    "    factor_ic_list = []\n",
    "    for factor_name in factor_list:\n",
    "        tmp_factor_ic = merge_df.groupby(['tradeDate']).apply(\n",
    "            lambda x: x[[factor_name, return_col_name]].corr(method=ic_type).values[0, 1])\n",
    "        tmp_factor_ic.name = factor_name\n",
    "        factor_ic_list.append(tmp_factor_ic)\n",
    "    factor_ic_frame = pd.concat(factor_ic_list, axis=1)\n",
    "    factor_ic_frame.reset_index(inplace=True)\n",
    "    return factor_ic_frame\n",
    "\n",
    "\n",
    "############################################################################################\n",
    "# Usage: monthly_factor_ic(factor_frame,['LCAP', 'PE'], month_len=3)\n",
    "############################################################################################\n",
    "# 输入因子的dataframe，计算月度因子的IC序列（未来1个月，n个月，可自定义）\n",
    "def monthly_factor_ic(factor_df, factor_list, start_date=None, end_date=None, ic_type='spearman', month_len=1):\n",
    "    '''\n",
    "    factor_df: panel/横截面/时间序列数据, 列至少包括: ['ticker','tradeDate', factor_list], tradeDate为 \"%Y%m%d\", 必须为月末日期\n",
    "    factor_list: 需要计算IC的factor名list\n",
    "    start_date: 返回的IC序列的最早时间，默认为None，和factor_df的最早时间保持一致；如果不为None, 格式为\"%Y%m%d, 必须为月末日期\n",
    "    end_date: 返回的IC序列的最大时间，默认为None，和factor_df的最大时间保持一致；如果不为None, 格式为\"%Y%m%d， 必须为月末日期\n",
    "    ic_type: spearman/pearson\n",
    "    month_len: 计算IC时，看和未来N期收益的关系\n",
    "    返回：\n",
    "         IC的dataframe，columns为：[tradeDate, factor1_name, factor2_name,..., factorn_name]]\n",
    "    '''\n",
    "    if start_date is None:\n",
    "        start_date = min(factor_df.tradeDate.values)\n",
    "    else:\n",
    "        start_date = max(str(start_date).replace(\"-\", \"\"), min(factor_df.tradeDate.values))\n",
    "\n",
    "    if end_date is None:\n",
    "        end_date = max(factor_df.tradeDate.values)\n",
    "    else:\n",
    "        end_date = min(str(end_date).replace(\"-\", \"\"), max(factor_df.tradeDate.values))\n",
    "    factor_df = factor_df.query(\"(tradeDate>=@start_date) & (tradeDate<=@end_date)\")\n",
    "\n",
    "    # 由于计算IC用到未来期的收益，所以取行情数据的截止日应该比因子的截止日多month_len期\n",
    "    date_frame = DataAPI.TradeCalGet(exchangeCD=u\"XSHG\", beginDate=end_date, field=u\"\", pandas=\"1\")\n",
    "    date_frame = date_frame.query(\"isMonthEnd==1\")\n",
    "    if len(date_frame) < (month_len + 1):\n",
    "        raise Exception(u\"计算月度IC时，交易日历中取不到%s的下个月月末日期，请检查%s是否为月末交易日\" % (end_date, end_date))\n",
    "    data_end_date = date_frame.head(month_len + 1).calendarDate.values[-1].replace(\"-\", \"\")\n",
    "\n",
    "    ticker_list = list(np.unique(factor_df.ticker.values))\n",
    "\n",
    "    # 获得月收益率\n",
    "    month_return = DataAPI.MktEqumGet(ticker=ticker_list, beginDate=start_date, endDate=data_end_date,\n",
    "                                      field=[\"ticker\", \"endDate\", \"closePrice\"], pandas=\"1\")\n",
    "    month_return.rename(columns={'endDate': 'tradeDate'}, inplace=True)\n",
    "    month_return['tradeDate'] = month_return['tradeDate'].apply(lambda x: x.replace(\"-\", \"\"))\n",
    "    month_return.sort_values(['ticker', 'tradeDate'], inplace=True)\n",
    "    # 计算未来month_len期的累计收益率\n",
    "    month_return['target_closePrice'] = month_return.groupby('ticker')['closePrice'].shift(-1 * month_len)\n",
    "    month_return['target_return'] = (month_return['target_closePrice'] - month_return['closePrice']) / month_return[\n",
    "        'closePrice']\n",
    "    month_return = month_return[['ticker', 'tradeDate', 'target_return', 'closePrice']]\n",
    "    month_return.dropna(inplace=True)\n",
    "\n",
    "    # 得到IC值\n",
    "    factor_ic_frame = calc_ic(factor_df, month_return, factor_list)\n",
    "    factor_ic_frame = factor_ic_frame[['tradeDate'] + factor_list]\n",
    "    factor_return_frame = factor_df.merge(month_return, on=['ticker', 'tradeDate'])\n",
    "    return factor_ic_frame, factor_return_frame\n",
    "\n",
    "\n",
    "############################################################################################\n",
    "# Usage: multifactor_icir_comb(factor_frame,['LCAP', 'PE'], 3, month_len=3)\n",
    "############################################################################################\n",
    "# 根据过去N期的IC_IR，得到因子的权重和加权得到的因子值\n",
    "def multifactor_icir_comb(factor_df, factor_list, window, ic_type='spearman', month_len=1, start_date=None,\n",
    "                          end_date=None):\n",
    "    '''\n",
    "    factor_df: panel数据, 列至少包括: ['ticker','tradeDate', factor_list], tradeDate为 \"%Y%m%d\", 必须为月末日期\n",
    "    factor_list: 参与权重分配的factor名list\n",
    "    start_date: 返回权重的最早时间，默认为None，和factor_df的最早时间保持一致；如果不为None, 格式为\"%Y%m%d, 必须为月末日期\n",
    "    end_date: 返回的权重的最大时间，默认为None，和factor_df的最大时间保持一致；如果不为None, 格式为\"%Y%m%d， 必须为月末日期\n",
    "    ic_type: spearman/pearson\n",
    "    返回：\n",
    "         factor_weight_frame： 列为: ['tradeDate', factor_name1, factor_name2, ...factor_nameN], 同一个tradeDate，权重之和为1\n",
    "         factor_frame：加上了合成因子值后的factor_frame, 列为['ticker', 'tradeDate', factor_list(原始因子值), 'multifactor_comb_value']\n",
    "    '''\n",
    "    # 调整factor_df的index，防止有duplicated的index\n",
    "    ori_factor_df_index = factor_df.index.values\n",
    "    factor_df.index = range(len(factor_df))\n",
    "    factor_df = factor_df[['ticker', 'tradeDate'] + factor_list]\n",
    "    # 得到因子每个月的IC\n",
    "    factor_ic_frame, factor_return_frame = monthly_factor_ic(factor_df, factor_list)\n",
    "    # 计算IC_IR值\n",
    "    factor_ic_frame.sort_values(by=['tradeDate'], inplace=True)\n",
    "    factor_icir_frame = factor_ic_frame.copy()\n",
    "    factor_icir_frame[factor_list] = factor_ic_frame[factor_list].shift(month_len).rolling(window=window).apply(\n",
    "        lambda x: x.mean() / x.std())\n",
    "    # 得到因子的权重值（根据横截面的IC_IR做归一化）, 权重frame的列为\n",
    "    factor_weight_frame = factor_icir_frame.copy()\n",
    "    # for factor_name in factor_list:\n",
    "    #     factor_weight_frame[factor_name] = factor_icir_frame[factor_name]/factor_icir_frame[factor_list].sum(axis=1)\n",
    "\n",
    "    # 将因子权重乘以原始因子值，得到合成之后的因子值\n",
    "    factor_df = factor_df.merge(factor_weight_frame, on=['tradeDate'], how='left', suffixes=(\"\", \"_weight\"))\n",
    "    weight_cols = [x + \"_weight\" for x in factor_list]\n",
    "    factor_df['multifactor_comb_value'] = (np.array(factor_df[factor_list]) * (np.array(factor_df[weight_cols]))).sum(\n",
    "        axis=1)\n",
    "\n",
    "    if start_date is None:\n",
    "        start_date = min(factor_df.tradeDate.values)\n",
    "    else:\n",
    "        start_date = max(str(start_date).replace(\"-\", \"\"), min(factor_df.tradeDate.values))\n",
    "\n",
    "    if end_date is None:\n",
    "        end_date = max(factor_df.tradeDate.values)\n",
    "    else:\n",
    "        end_date = min(str(end_date).replace(\"-\", \"\"), max(factor_df.tradeDate.values))\n",
    "    factor_df = factor_df.query(\"(tradeDate>=@start_date) & (tradeDate<=@end_date)\")\n",
    "    factor_weight_frame = factor_weight_frame.query(\"(tradeDate>=@start_date) & (tradeDate<=@end_date)\")\n",
    "    return factor_df, [factor_weight_frame, factor_return_frame]\n",
    "\n",
    "\n",
    "############################################################################################\n",
    "# Usage: fin_data_pit2cont(factor_frame,'20160101', '20171231')\n",
    "############################################################################################\n",
    "# 将PIT数据转成连续数据\n",
    "def fin_data_pit2cont(pit_data_frame, sdate, edate):\n",
    "    \"\"\"\n",
    "    将PIT数据转成连续数据\n",
    "    pit_data_frame: 财务报表数据, column= ['ticker','pub_date',[fin_value]], index=num, pub_date='%Y%m%d'\n",
    "    sdate: 起始时间, '%Y%m%d'\n",
    "    edate: 终止时间, '%Y%m%d'\n",
    "    返回：\n",
    "         连续日的因子值dataframe, 列为：['ticker','pub_date',[fin_value]]\n",
    "    \"\"\"\n",
    "\n",
    "    trade_date_frame = DataAPI.TradeCalGet(exchangeCD=u\"XSHE\", beginDate='20060101', endDate=edate,\n",
    "                                           field=['calendarDate', 'isOpen'])\n",
    "    trade_date_frame.rename(columns={\"calendarDate\": \"pub_date\"}, inplace=True)\n",
    "    trade_date_frame['pub_date'] = trade_date_frame['pub_date'].apply(lambda x: str(x).replace('-', ''))\n",
    "\n",
    "    tmp_frame = pit_data_frame.groupby(['ticker']).apply(lambda x: x.merge(trade_date_frame,\n",
    "                                                                           on=['pub_date'], how='outer'))\n",
    "    del tmp_frame['ticker']\n",
    "    tmp_frame.reset_index(inplace=True)\n",
    "    del tmp_frame['level_1']\n",
    "\n",
    "    tmp_frame = tmp_frame.sort_values(by=['ticker', 'pub_date'], ascending=True)\n",
    "    tmp_frame = tmp_frame.groupby(['ticker']).apply(lambda x: x.fillna(method='pad'))\n",
    "    tmp_frame.dropna(inplace=True)\n",
    "    tmp_frame = tmp_frame[tmp_frame.pub_date >= sdate]\n",
    "    tmp_frame = tmp_frame[tmp_frame.isOpen == 1]\n",
    "    del tmp_frame['isOpen']\n",
    "    return tmp_frame\n",
    "\n",
    "\n",
    "############################################################################################\n",
    "# Usage: stock_special_tag('20160101', '20171231')\n",
    "############################################################################################\n",
    "# 某一时间区间内，根据股票的是否满足某些条件，打上标签\n",
    "def stock_special_tag(start_date, end_date, halt=1, st=1, pre_new=1, pre_new_length=60):\n",
    "    '''\n",
    "    某一时间区间内，根据股票的是否满足某些条件，打上标签\n",
    "    start_date: 起始时间, %Y%m%d\n",
    "    end_date: 结束时间, %Y%m%d\n",
    "    halt: 停牌\n",
    "    st: 正处于ST状态\n",
    "    pre_new: 次新股\n",
    "    pre_new_length: 定义新股上市后 pre_new_length的股票为次新股\n",
    "    返回：\n",
    "         tag_df：包含标签的dataframe， 列为： ['ticker', 'tradeDate', 'special_flag']\n",
    "         special_flag为：{如果停牌，则为'halt'， 如果ST，则为'ST', 如果次新股，则为'new'}，一个股票在同一天如果满足多个条件，会有多条记录（多行）\n",
    "    '''\n",
    "    \n",
    "    start_date = start_date[:4]+'-'+start_date[4:6]+'-'+start_date[6:]\n",
    "    end_date = end_date[:4]+'-'+end_date[4:6]+'-'+end_date[6:]\n",
    "    # 获取交易日历\n",
    "    trade_calendar = DataAPI.TradeCalGet(exchangeCD=U\"XSHG\", field=u\"calendarDate,isOpen,isMonthEnd\")\n",
    "\n",
    "    # 获得交易日历\n",
    "    calendar = trade_calendar[trade_calendar['isOpen'] == 1]\n",
    "    calendar = calendar['calendarDate'].tolist()\n",
    "\n",
    "    # 次新股\n",
    "    new_df = pd.DataFrame(columns=['ticker', 'tradeDate', 'special_flag'])\n",
    "    if pre_new:\n",
    "        ipo_info = DataAPI.SecIDGet(assetClass=u\"E\", field=['ticker', 'listDate'], pandas=\"1\")\n",
    "        ipo_info.dropna(inplace=True)\n",
    "        ticker_list = [ticker for ticker in ipo_info['ticker'] if len(ticker) == 6 and ticker[0] in ['0', '3', '6']]\n",
    "        ipo_info = ipo_info[ipo_info['ticker'].isin(ticker_list)]\n",
    "        ipo_info['permit_idx'] = [calendar.index(date) + int(pre_new_length) if date in calendar else  int(pre_new_length) for date in ipo_info['listDate']]\n",
    "        ipo_info['permit_date'] = [calendar[idx] if idx <= len(calendar) else  calendar[-1] for idx in ipo_info['permit_idx']]\n",
    "\n",
    "        calendar = np.array(calendar)\n",
    "        new_df_list = []\n",
    "        for date in calendar[(calendar >= start_date) & (calendar <= end_date)]:\n",
    "            new_list = ipo_info[(ipo_info['permit_date'] >= date) & (ipo_info['listDate'] <= date)]['ticker'].values\n",
    "            d_new_df = pd.DataFrame({'tradeDate': [date] * len(new_list), 'ticker': new_list})\n",
    "            new_df_list.append(d_new_df)\n",
    "\n",
    "        new_df = pd.concat(new_df_list, axis=0)\n",
    "        new_df['special_flag'] = 'new'\n",
    "\n",
    "    # ST股\n",
    "    st_df = pd.DataFrame(columns=['ticker', 'tradeDate', 'special_flag'])\n",
    "    if st:\n",
    "        st_info = DataAPI.SecSTGet(beginDate=start_date, endDate=end_date, field=['tradeDate', 'ticker'], pandas=\"1\")\n",
    "        st_df = st_info.copy()\n",
    "        st_df['special_flag'] = 'st'\n",
    "\n",
    "    # 停牌\n",
    "    halt_df = pd.DataFrame(columns=['ticker', 'tradeDate', 'special_flag'])\n",
    "    if halt:\n",
    "        halt_info = DataAPI.SecHaltGet(beginDate=start_date, endDate=end_date,\n",
    "                                       field=['ticker', 'haltBeginTime', 'haltEndTime'], pandas=\"1\")\n",
    "        halt_info.fillna(calendar[-1], inplace=True)\n",
    "        halt_info['haltBeginTime'] = halt_info['haltBeginTime'].apply(lambda x: x[:10])\n",
    "        halt_info['haltEndTime'] = halt_info['haltEndTime'].apply(lambda x: x[:10])\n",
    "\n",
    "        halt_df_list = []\n",
    "        for date in calendar[(calendar >= start_date) & (calendar <= end_date)]:\n",
    "            halt_list = halt_info[(halt_info['haltEndTime'] >= date) & (halt_info['haltBeginTime'] <= date)][\n",
    "                'ticker'].values\n",
    "            d_halt_df = pd.DataFrame({'tradeDate': [date] * len(halt_list), 'ticker': halt_list})\n",
    "            halt_df_list.append(d_halt_df)\n",
    "\n",
    "        halt_df = pd.concat(halt_df_list, axis=0)\n",
    "        halt_df['special_flag'] = 'halt'\n",
    "\n",
    "    tag_df = pd.concat([new_df, st_df, halt_df], axis=0)\n",
    "    tag_df = tag_df[['ticker', 'tradeDate', 'special_flag']]\n",
    "    tag_df['tradeDate'] = tag_df['tradeDate'].apply(lambda x: x.replace(\"-\", \"\"))\n",
    "    return tag_df\n",
    "\n",
    "\n",
    "############################################################################################\n",
    "# Usage: get_performance(bt)\n",
    "############################################################################################\n",
    "# 根据优矿的回测结果（或者类似的回测数据）计算净值和回撤\n",
    "def get_performance(bt, excess=False):\n",
    "    '''\n",
    "    得到回测结果的净值和回撤\n",
    "    bt: dataframe，columns至少为：['tradeDate', u'portfolio_value',u'benchmark_return']\n",
    "    excess: 如果为True, 则收益代表超额收益，否则为绝对收益\n",
    "    返回：\n",
    "         return_data: 净值序列dataframe, 列为:['tradeDate', 'portfolio_value','portfolio_return','target_return'], 'target_return'为绝对或者超额的累计收益率\n",
    "         drawback_data:最大回撤序列\n",
    "    '''\n",
    "    return_data = bt[[u'tradeDate', u'portfolio_value', u'benchmark_return']].set_index('tradeDate')\n",
    "    if type(bt.tradeDate.values[0]) == np.datetime64:\n",
    "        return_data.index = pd.to_datetime(return_data.index)\n",
    "    return_data['portfolio_return'] = return_data.portfolio_value.pct_change()\n",
    "    return_data['portfolio_return'].ix[0] = 0\n",
    "    if excess:\n",
    "        return_data['target_return'] = return_data.portfolio_return - data.benchmark_return\n",
    "    else:\n",
    "        return_data['target_return'] = return_data.portfolio_return\n",
    "    return_data['target'] = return_data.target_return + 1.0\n",
    "    return_data['target_return'] = return_data.target.cumprod()\n",
    "    del return_data['target']\n",
    "\n",
    "    df_cum_rets = return_data['portfolio_return']\n",
    "    running_max = np.maximum.accumulate(df_cum_rets)\n",
    "    drawback_data = -((running_max - df_cum_rets) / running_max)\n",
    "    return return_data, drawback_data\n",
    "\n",
    "############################################################################################\n",
    "# Usage: signal_grouping(factor_frame, 'LCAP', ngrp=5)\n",
    "############################################################################################\n",
    "def signal_grouping(signal_df, factor_name, ngrp):\n",
    "    \"\"\"\n",
    "    因子分组， 每天根据因子值将股票进行等分，编号0 ~ ngrp-1, 编号越大， 因子值越大\n",
    "    params:\n",
    "            signal_df: DataFrame, columns=['ticker', 'tradeDate', [factor]], 股票的因子值, factor一类为股票当日的因子值\n",
    "            factor_name:　str, signal_df中因子值的列名\n",
    "            ngrp: int, 分组组数\n",
    "    return:\n",
    "            DataFrame, signal_df在原本的基础上增加一列'group', 记录每日分组\n",
    "    \"\"\"\n",
    "    signal_df_tmp = signal_df.copy()\n",
    "    signal_df_tmp.dropna(subset=[factor_name], inplace=True)\n",
    "    signal_df_tmp['group'] = signal_df_tmp.groupby('tradeDate')[factor_name].apply(\n",
    "        lambda x: (x.rank(method='first') - 1) / len(x) * ngrp).astype(int)\n",
    "    return signal_df_tmp\n",
    "\t\n",
    "############################################################################################\n",
    "# Usage: long_short_backtest(factor_frame, return_df, return_name='nxt_ret')\n",
    "############################################################################################\n",
    "def long_short_backtest(signal_df, return_df, factor_name, return_name, direction=1):\n",
    "    \"\"\"\n",
    "    简易因子多空回测组合， 根据因子值将个股等分成5组，根据方向指定， 正向操作：做多因子值最大的一组， 做空因子值最小的一组；反向操作：做空因子值最大的一组， 做多因子值最小的一组。\n",
    "    根据调仓频率，进行交易，返回最后的累计收益率。\n",
    "    params:\n",
    "            signal_df: DataFrame, columns=['ticker', 'tradeDate', [factor]], 股票的因子值, factor一类为股票当日的因子值\n",
    "            return_df: DataFrame, columns=['ticker', 'tradeDate', [period_return]], 收益率，只含有调仓日，以及下期累计收益率\n",
    "            factor_name:　str, signal_df中因子值的列名\n",
    "            return_name： str, return_df中收益率的列名\n",
    "            direction： {1,-1}, 操作方向， 1为正向操作， 2为反向操作， 默认为1\n",
    "    return:\n",
    "            DataFrame, columns=['tradeDate', 'cum_ret'], 返回累计收益率\n",
    "    \"\"\"\n",
    "    bt_df = signal_df.merge(return_df, on=['ticker', 'tradeDate'], how='right')\n",
    "\n",
    "    # 分成五祖, 保留因子值最大和最小的两组\n",
    "    bt_df.dropna(subset=[factor_name, return_name], inplace=True)\n",
    "    bt_df = signal_grouping(bt_df, factor_name=factor_name, ngrp=5)\n",
    "    bt_df = bt_df[bt_df['group'].isin([0, 4])]\n",
    "\n",
    "    # 计算权重：每组等权\n",
    "    count_df = bt_df.groupby(['tradeDate', 'group']).apply(lambda x: len(x)).reset_index()\n",
    "    count_df.columns = ['tradeDate', 'group', 'count']\n",
    "    bt_df = bt_df.merge(count_df, on=['tradeDate', 'group'])\n",
    "    bt_df['weight'] = 1.0 / bt_df['count']\n",
    "\n",
    "    # 如果direction=1, 则做多因子值最大的一组， 做空因子值最小的一组；如果direction=-1, 则做空因子值最大的一组， 做多因子值最小的一组\n",
    "    bt_df.loc[bt_df['group'] == 4, 'weight'] = bt_df.loc[bt_df['group'] == 4, 'weight'] * direction\n",
    "    bt_df.loc[bt_df['group'] == 0, 'weight'] = bt_df.loc[bt_df['group'] == 0, 'weight'] * (-direction) * 0\n",
    "\n",
    "    perf = bt_df.groupby('tradeDate').apply(lambda x: sum(x[return_name] * x['weight'])).reset_index()\n",
    "    perf.columns = ['tradeDate', 'period_ret']\n",
    "    perf.sort_values('tradeDate', inplace=True)\n",
    "    perf['cum_ret'] = (perf['period_ret'] + 1).cumprod()\n",
    "\n",
    "    # 调整时间\n",
    "    perf['period_ret'] = perf['period_ret'].shift(1)\n",
    "    perf.fillna(0, inplace=True)\n",
    "    perf['cum_ret'] = perf['cum_ret'].shift(1)\n",
    "    perf.fillna(1, inplace=True)\n",
    "\n",
    "    return perf[['tradeDate', 'period_ret', 'cum_ret']], bt_df\n",
    "\n",
    "############################################################################################\n",
    "# Usage: easy_backtest(factor_frame, return_df, factor_name='PE', return_name='nxt_ret')\n",
    "############################################################################################\n",
    "def easy_backtest(signal_df, return_df, factor_name, return_name, method='long_short', direction=1, ngrp=5, weight_schemes=0, weights=None, commission=0):\n",
    "    \"\"\"\n",
    "    简易因子回测组合， 根据指定分组方式、指定回测方式，进行多空回测或纯多头回测。若原因子数据没有分组信息，则默认按因子值进行等分分组。\n",
    "    根据方向指定， 正向操作：做多因子值最大的一组， 做空因子值最小的一组；反向操作：做空因子值最大的一组， 做多因子值最小的一组。\n",
    "    根据调仓频率，进行交易，返回每期收益率和累计收益率。\n",
    "    params:\n",
    "            signal_df: DataFrame, columns=['ticker', 'tradeDate', [factor]], 股票的因子值, factor一类为股票当日的因子值\n",
    "            return_df: DataFrame, columns=['ticker', 'tradeDate', [period_return]], 收益率，只含有调仓日，以及下期累计收益率\n",
    "            factor_name:　str, signal_df中因子值的列名\n",
    "            return_name： str, return_df中收益率的列名\n",
    "            method: {'long_only', 'long_only'}, 'long_only'纯多头回测, 'long_short'多空回测\n",
    "            direction: {1,-1}, 1因子为正向, -1因子为反向\n",
    "            ngrp: 因子分组的组数， 默认分5组\n",
    "            weight_schemes: {0,1}. 0等权配置, 1自定义加权配置,需要给定weights\n",
    "            weights: 当weight_schemes = 1时，weights为权重方式。\n",
    "            commission: float, 交易费用设置, 卖出时收取，默认不考虑交易费\n",
    "\n",
    "    return:\n",
    "            DataFrame, columns=['tradeDate', 'period_ret', 'cum_ret'], 返回每期收益率和累计收益率\n",
    "    \"\"\"\n",
    "    bt_df = signal_df.merge(return_df, on=['ticker', 'tradeDate'], how='right')\n",
    "\n",
    "    # 因子分组\n",
    "    bt_df.dropna(subset=[factor_name, return_name], inplace=True)\n",
    "    if 'group' not in bt_df.columns:\n",
    "        bt_df = signal_grouping(bt_df, factor_name=factor_name, ngrp=ngrp)\n",
    "\n",
    "    if method == 'long_short':\n",
    "        # 保留因子值最大和最小的两组\n",
    "        bt_df = bt_df[bt_df['group'].isin([0, ngrp - 1])]\n",
    "    elif method == 'long_only':\n",
    "        if direction == 1:\n",
    "            bt_df = bt_df[bt_df['group'].isin([ngrp - 1])]\n",
    "        elif direction == -1:\n",
    "            bt_df = bt_df[bt_df['group'].isin([0])]\n",
    "\n",
    "    # 加权方式\n",
    "    if weight_schemes == 0:\n",
    "        # 计算权重：每组等权\n",
    "        count_df = bt_df.groupby(['tradeDate', 'group']).apply(lambda x: len(x)).reset_index()\n",
    "        count_df.columns = ['tradeDate', 'group', 'count']\n",
    "        bt_df = bt_df.merge(count_df, on=['tradeDate', 'group'])\n",
    "        bt_df['weight'] = 1.0 / bt_df['count']\n",
    "    elif weight_schemes == 1:\n",
    "        # 计算权重：自定义加权\n",
    "        bt_df = bt_df.merge(weights, on=['ticker', 'tradeDate'])\n",
    "        bt_df.sort_values(['group', 'tradeDate'], inplace=True)\n",
    "        bt_df['weight'] = bt_df.groupby(['group', 'tradeDate'])['weight'].apply(lambda x: x / sum(x)).values\n",
    "\n",
    "    if method == 'long_short':\n",
    "        # 如果direction=1, 则做多因子值最大的一组， 做空因子值最小的一组；如果direction=-1, 则做空因子值最大的一组， 做多因子值最小的一组\n",
    "        bt_df.loc[bt_df['group'] == ngrp - 1, 'weight'] = bt_df.loc[bt_df['group'] == ngrp - 1, 'weight'] * direction /2.0\n",
    "        bt_df.loc[bt_df['group'] == 0, 'weight'] = bt_df.loc[bt_df['group'] == 0, 'weight'] * (-direction) /2.0\n",
    "\n",
    "    perf = bt_df.groupby('tradeDate').apply(lambda x: sum(x[return_name] * x['weight'])).reset_index()\n",
    "    perf.columns = ['tradeDate', 'period_ret']\n",
    "    if commission > 0:\n",
    "        # 在卖出时收取交易费用\n",
    "        adj_df = bt_df.pivot_table(values='weight', index='tradeDate', columns='ticker').fillna(0)\n",
    "        adj_df1 = adj_df.diff().fillna(0)\n",
    "        comm = (adj_df1[adj_df1<0]* commission).sum(axis=1).fillna(0).reset_index()\n",
    "        comm.columns = ['tradeDate', 'cost']\n",
    "        perf = perf.merge(comm, on=['tradeDate'])\n",
    "        perf['period_ret'] = perf['period_ret'] + perf['cost']\n",
    "    perf.sort_values('tradeDate', inplace=True)\n",
    "    perf['cum_ret'] = (perf['period_ret'] + 1).cumprod()\n",
    "\n",
    "    # 调整时间\n",
    "    perf['period_ret'] = perf['period_ret'].shift(1)\n",
    "    perf.fillna(0, inplace=True)\n",
    "    perf['cum_ret'] = perf['cum_ret'].shift(1)\n",
    "    perf.fillna(1, inplace=True)\n",
    "\n",
    "    return perf[['tradeDate', 'period_ret', 'cum_ret']], bt_df\n",
    "\n",
    "############################################################################################\n",
    "# Usage: easy_backtest(factor_frame, return_df, factor_name='PE', return_name='nxt_ret')\n",
    "############################################################################################\n",
    "def simple_group_backtest(signal_df, return_df, factor_name, return_name, ngrp=5, commission=0):\n",
    "    \"\"\"\n",
    "    对因子进行简单的分组多头回测。返回各组收益率和累计收益率， 编号越大，因子值越大。\n",
    "    参数：\n",
    "        signal_df: DataFrame, columns=['ticker', 'tradeDate', [factor]], 股票的因子值, factor一类为股票当日的因子值\n",
    "        return_df: DataFrame, columns=['ticker', 'tradeDate', [period_return]], 收益率，只含有调仓日，以及下期累计收益率\n",
    "        factor_name:　str, signal_df中因子值的列名\n",
    "        return_name： str, return_df中收益率的列名\n",
    "        ngrp: int, 分组数, 默认为5\n",
    "        commission: float, 交易费用设置, 卖出时收取，默认不考虑交易费\n",
    "    返回：\n",
    "        DataFrame, 列为[’group'， tradeDate', 'period_ret', 'cum_ret'], 返回每期收益率和累计收益率\n",
    "    \"\"\"\n",
    "    bt_df = signal_df.merge(return_df, on=['ticker', 'tradeDate'], how='right')\n",
    "    \n",
    "    # 因子分组\n",
    "    bt_df.dropna(subset=[factor_name, return_name], inplace=True)\n",
    "    bt_df = signal_grouping(bt_df, factor_name=factor_name, ngrp=ngrp)\n",
    "    \n",
    "    # 等权\n",
    "    count_df = bt_df.groupby(['tradeDate', 'group']).apply(lambda x: len(x)).reset_index()\n",
    "    count_df.columns = ['tradeDate', 'group', 'count']\n",
    "    bt_df = bt_df.merge(count_df, on=['tradeDate', 'group'])\n",
    "    bt_df['weight'] = 1.0 / bt_df['count']\n",
    "    \n",
    "    perf = bt_df.groupby(['group', 'tradeDate']).apply(lambda x: sum(x[return_name] * x['weight'])).reset_index()\n",
    "    perf.columns = ['group', 'tradeDate', 'period_ret']\n",
    "    if commission > 0:\n",
    "        # 在卖出时收取交易费用\n",
    "        adj_df = bt_df.pivot_table(values='weight', index='tradeDate', columns=['group', 'ticker']).fillna(0)\n",
    "        adj_df1 = adj_df.diff().fillna(0)\n",
    "        comm = (adj_df1[adj_df1<0]* commission).sum(level='group', axis=1).fillna(0)\n",
    "        comm = comm.stack().reset_index()\n",
    "        comm.columns = ['tradeDate', 'group', 'cost']\n",
    "        perf = perf.merge(comm, on=['group', 'tradeDate'])\n",
    "        perf['period_ret'] = perf['period_ret'] + perf['cost']\n",
    "    perf.sort_values(['group', 'tradeDate'], inplace=True)\n",
    "    perf['cum_ret'] = perf.groupby('group')['period_ret'].apply(lambda x: (x+1).cumprod())\n",
    "    \n",
    "    # 调整时间\n",
    "    perf['period_ret'] = perf.groupby('group')['period_ret'].shift(1)\n",
    "    perf['period_ret'].fillna(0, inplace=True)\n",
    "    perf['cum_ret'] = perf.groupby('group')['cum_ret'].shift(1)\n",
    "    perf['cum_ret'].fillna(1, inplace=True)\n",
    "    \n",
    "    return perf[['group', 'tradeDate', 'period_ret', 'cum_ret']], bt_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
