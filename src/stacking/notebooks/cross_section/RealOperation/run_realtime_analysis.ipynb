{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 基础因子实时计算"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "zz500模拟盘操作, 每5天更新."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "sys.path.append('../../')\n",
    "sys.path.append('../../../')\n",
    "sys.path.append('../../../../')\n",
    "sys.path.append('../../../../../')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from PyFin.api import *\n",
    "from alphamind.api import *\n",
    "from conf.models import *\n",
    "from conf.config import*\n",
    "from data.engines.model import Record\n",
    "from alphamind.execution.naiveexecutor import NaiveExecutor\n",
    "from stacking import factor_store, feature_list\n",
    "from optimization.bayesopt.bayes_optimization_xgb import *\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('max_colwidth',100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 因子数据准备"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设置train和predict日期\n",
    "start_date = '2019-12-06'  # trainning起始时间\n",
    "end_date = '2020-02-23'    # predict时间, 调仓日, 目前中间隔段大概有10个调仓日\n",
    "\n",
    "# 设置交易日\n",
    "trade_end_date = '2020-02-24'  # 当前交易日期[predict的下一个交易日作为下单调仓日]\n",
    "\n",
    "# 设置保存的文件目录\n",
    "weekly = 's1'  # 文件目录\n",
    "freq = '5b'\n",
    "\n",
    "# 换手率控制\n",
    "turn_over_rate = 0.5  # {s1:0.5, s2:0.3, s3:0.6, s4:0.8, s5:0.5}\n",
    "\n",
    "# 组合优化参数\n",
    "weight_gap = 0.02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "前一个调仓日: 2020-02-14 00:00:00\n",
      "当前调仓日: 2020-02-21 00:00:00\n",
      "前一个交易日: 2020-02-17 00:00:00\n",
      "当前交易日: 2020-02-24 00:00:00\n"
     ]
    }
   ],
   "source": [
    "universe = Universe('zz500')\n",
    "benchmark_code = 905\n",
    "ref_dates = makeSchedule(start_date, end_date, freq, 'china.sse')\n",
    "horizon = map_freq(freq)\n",
    "industry_name = 'sw'\n",
    "industry_level = 1\n",
    "\n",
    "# 根据索引删除某些特殊日期{节假日, 零时停盘日等}\n",
    "trash_date_list = [datetime(2020, 1, 1, 0, 0), \n",
    "                   datetime(2020, 1, 23, 0, 0),\n",
    "                   datetime(2020, 1, 24, 0, 0),\n",
    "                   datetime(2020, 1, 25, 0, 0),\n",
    "                   datetime(2020, 1, 26, 0, 0),\n",
    "                   datetime(2020, 1, 27, 0, 0),\n",
    "                   datetime(2020, 1, 28, 0, 0),\n",
    "                   datetime(2020, 1, 29, 0, 0),                   \n",
    "                   datetime(2020, 1, 30, 0, 0),\n",
    "                   datetime(2020, 1, 31, 0, 0),\n",
    "                  ]\n",
    "a = []\n",
    "for i in trash_date_list:\n",
    "    try:\n",
    "        del(ref_dates[ref_dates.index(i)])\n",
    "    except:\n",
    "        continue\n",
    "\n",
    "ref_dates = ref_dates[-10:]\n",
    "# 调仓日表示因子数据入库完成之后, 模型训练的日期(当前已收盘),\n",
    "# 交易日表示实际交易的日期, 策略中为调仓日的下一个交易日\n",
    "# 前一个调仓日\n",
    "ref_date_pre = ref_dates[-2]\n",
    "# 当前调仓日\n",
    "ref_date = ref_dates[-1]\n",
    "print('前一个调仓日: %s' % ref_date_pre)\n",
    "print('当前调仓日: %s' % ref_date)\n",
    "\n",
    "# 获取前一个交易日, 用于获取前一个调仓日的持仓信息\n",
    "date_range = makeSchedule(ref_date_pre, trade_end_date, '1d', 'china.sse')\n",
    "# 前一个交易日, 如果遇到上一个调仓日存在空缺如[2020.01.01], 需要特殊指定\n",
    "# adjusted_date_pre = datetime(2020, 1, 11, 0, 0)\n",
    "adjusted_date_pre = date_range[1]\n",
    "# 当前交易日\n",
    "adjusted_date = date_range[-1]\n",
    "\n",
    "print('前一个交易日: %s' % adjusted_date_pre)\n",
    "print('当前交易日: %s' % adjusted_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[datetime.datetime(2020, 2, 14, 0, 0),\n",
       " datetime.datetime(2020, 2, 17, 0, 0),\n",
       " datetime.datetime(2020, 2, 18, 0, 0),\n",
       " datetime.datetime(2020, 2, 19, 0, 0),\n",
       " datetime.datetime(2020, 2, 20, 0, 0),\n",
       " datetime.datetime(2020, 2, 21, 0, 0),\n",
       " datetime.datetime(2020, 2, 24, 0, 0)]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "date_range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[datetime.datetime(2019, 12, 6, 0, 0),\n",
       " datetime.datetime(2019, 12, 13, 0, 0),\n",
       " datetime.datetime(2019, 12, 20, 0, 0),\n",
       " datetime.datetime(2019, 12, 27, 0, 0),\n",
       " datetime.datetime(2020, 1, 3, 0, 0),\n",
       " datetime.datetime(2020, 1, 10, 0, 0),\n",
       " datetime.datetime(2020, 1, 17, 0, 0),\n",
       " datetime.datetime(2020, 2, 7, 0, 0),\n",
       " datetime.datetime(2020, 2, 14, 0, 0),\n",
       " datetime.datetime(2020, 2, 21, 0, 0)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ref_dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'__main__'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "__name__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "{'start_date': '2019-12-06', 'end_date': '2020-02-23', 'trade_end_date': '2020-02-24', 'weekly': 's1', 'freq': '5b', 'turn_over_rate': 0.5, 'weight_gap': 0.02, 'adjusted_date_pre': datetime.datetime(2020, 2, 14, 0, 0), 'adjusted_date': datetime.datetime(2020, 2, 21, 0, 0), 'trade_date_pre': datetime.datetime(2020, 2, 17, 0, 0), 'trade_date': datetime.datetime(2020, 2, 24, 0, 0)}\n"
     ]
    }
   ],
   "source": [
    "## 日志\n",
    "## 将所有信息保存为日志文件\n",
    "import logging\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel(level = logging.INFO)\n",
    "handler = logging.FileHandler(\"./{}/logFile.txt\".format(weekly))\n",
    "handler.setLevel(logging.INFO)\n",
    "formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "handler.setFormatter(formatter)\n",
    "\n",
    "console = logging.StreamHandler()\n",
    "console.setLevel(logging.INFO)\n",
    " \n",
    "logger.addHandler(handler)\n",
    "logger.addHandler(console)\n",
    "\n",
    "log_file = {\n",
    "    'start_date': start_date,\n",
    "    'end_date': end_date,\n",
    "    'trade_end_date': trade_end_date,\n",
    "    'weekly': weekly,\n",
    "    'freq': freq,\n",
    "    'turn_over_rate': turn_over_rate,\n",
    "    'weight_gap': weight_gap,\n",
    "    'adjusted_date_pre': ref_date_pre,\n",
    "    'adjusted_date': ref_date,\n",
    "    'trade_date_pre': adjusted_date_pre,\n",
    "    'trade_date': adjusted_date,\n",
    "}\n",
    "logger.info(log_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# 因子数据库\n",
    "data_source = alpha_db\n",
    "engine = SqlEngine(data_source)\n",
    "\n",
    "# uqer因子列表\n",
    "basic_factor_store = factor_store.basic_factor_store\n",
    "# alpha191因子列表\n",
    "alpha_factor_store = factor_store.alpha_factor_store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 9.3 s, sys: 184 ms, total: 9.48 s\n",
      "Wall time: 10.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# 提取Uqer因子\n",
    "basic_factor_org = engine.fetch_factor_range(universe, basic_factor_store, dates=ref_dates)\n",
    "# 提取alpha191因子\n",
    "# alpha191_factor_org = engine.fetch_factor_range(universe, \n",
    "#                                                 alpha_factor_store, \n",
    "#                                                 dates=ref_dates, \n",
    "#                                                 used_factor_tables=[Alpha191]).drop(['chgPct','secShortName'], axis=1)\n",
    "# # 合并所有的因子\n",
    "# factor_data_org = pd.merge(basic_factor_org, alpha191_factor_org, on=['trade_date', 'code'], how='outer')\n",
    "factor_data_org = basic_factor_org\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{Timestamp('2019-12-06 00:00:00'),\n",
       " Timestamp('2019-12-13 00:00:00'),\n",
       " Timestamp('2019-12-20 00:00:00'),\n",
       " Timestamp('2019-12-27 00:00:00'),\n",
       " Timestamp('2020-01-03 00:00:00'),\n",
       " Timestamp('2020-01-10 00:00:00'),\n",
       " Timestamp('2020-01-17 00:00:00'),\n",
       " Timestamp('2020-02-07 00:00:00'),\n",
       " Timestamp('2020-02-14 00:00:00')}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(factor_data_org['trade_date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Factor Missing\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/workenv/vision/lib/python3.6/site-packages/IPython/core/interactiveshell.py:3299: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    assert len(set(factor_data_org['trade_date'])) == len(ref_dates)\n",
    "except:\n",
    "    logger.error(\"Factor Missing\")\n",
    "    sys.exit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot factor value over time on code\n",
    "from matplotlib import pyplot as plt\n",
    "from pylab import rcParams\n",
    "rcParams['figure.figsize'] = 10, 2 # width 10, height 8\n",
    "\n",
    "ax = factor_data_org[factor_data_org['code'] == 6].plot(x='trade_date', y='ACCA', style='b-', grid=True)\n",
    "ax.set_xlabel(\"date\")\n",
    "ax.set_ylabel(\"ACCA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 因子预处理\n",
    "## 确失值填充\n",
    "factor_mean = factor_data_org.mean()\n",
    "factor_std = factor_data_org.std()\n",
    "factor_data_org = factor_data_org.fillna(factor_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# 获取所属行业\n",
    "industry = engine.fetch_industry_range(universe, dates=ref_dates)\n",
    "# factor_data = pd.merge(factor_data_org, industry, on=['trade_date', 'code']).fillna(0.)\n",
    "factor_data = pd.merge(factor_data_org, industry, on=['trade_date', 'code'])\n",
    "\n",
    "# 获取风险因子\n",
    "risk_total = engine.fetch_risk_model_range(universe, dates=ref_dates)[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "return_data = engine.fetch_dx_return_range(universe, dates=ref_dates, horizon=horizon, offset=0, benchmark=benchmark_code)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "return_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "benchmark_total = engine.fetch_benchmark_range(dates=ref_dates, benchmark=benchmark_code)\n",
    "industry_total = engine.fetch_industry_matrix_range(universe, dates=ref_dates, category=industry_name, level=industry_level)\n",
    "\n",
    "train_data = pd.merge(factor_data, return_data, on=['trade_date', 'code']).dropna()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot adjusted close over time on code\n",
    "from matplotlib import pyplot as plt\n",
    "from pylab import rcParams\n",
    "rcParams['figure.figsize'] = 10, 2 # width 10, height 8\n",
    "\n",
    "ax = train_data[train_data['code'] == 6].plot(x='trade_date', y='dx', style='b-', grid=True)\n",
    "ax.set_xlabel(\"date\")\n",
    "ax.set_ylabel(\"dx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 获取特征名\n",
    "features = list(basic_factor_store.keys())\n",
    "alpha_features = list(alpha_factor_store.keys())\n",
    "# features = feature_list.uqer_features\n",
    "# alpha_features = feature_list.alpha_features\n",
    "# features.extend(alpha_features)\n",
    "\n",
    "label = ['dx']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "from models.m1_xgb import *\n",
    "from conf.configuration import xgb_conf\n",
    "from data.engines.model import Record\n",
    "import xgboost as xgb\n",
    "import gc\n",
    "\n",
    "alpha_logger.info('{0} is start'.format(ref_date))\n",
    "\n",
    "# machine learning model\n",
    "## Filter Training data\n",
    "## 训练集构造\n",
    "trade_date_pre = ref_date - timedelta(days=1)\n",
    "# trade_date_pre_80 = ref_date - timedelta(days=80)\n",
    "\n",
    "## 1、选择调仓日当天之前(不含当天)并且在80天以内的因子数据作为训练集.\n",
    "# train = train_data[(train_data.trade_date <= trade_date_pre) & (trade_date_pre_80 <= train_data.trade_date)].dropna()\n",
    "## 2、选择调仓日当天之前(不含当天)的因子数据作为训练集.\n",
    "train = train_data[train_data.trade_date <= trade_date_pre].dropna()\n",
    "alpha_logger.info('trade_date_pre {0}'.format(trade_date_pre))\n",
    "\n",
    "if len(train) <= 0:\n",
    "    alpha_logger.info('{0} HAS NO TRAIN DATA!!!'.format(ref_date))\n",
    "\n",
    "x_train = train[features]\n",
    "y_train = train[label]\n",
    "alpha_logger.info('len_x_train: {0}, len_y_train: {1}'.format(len(x_train.values), len(y_train.values)))\n",
    "alpha_logger.info('X_train.shape={0}, X_test.shape = {1}'.format(np.shape(x_train), np.shape(y_train)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 超参寻优"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load xgboost regression configuration\n",
    "xgb_conf.xgb_config_r()\n",
    "xgb_conf.cv_folds = None\n",
    "xgb_conf.early_stop_round = 100\n",
    "xgb_conf.max_round = 800\n",
    "xgb_conf.params.update({'nthread': 12})\n",
    "\n",
    "GPU_device = False\n",
    "if GPU_device:\n",
    "    # use GPUs\n",
    "    xgb_conf.params.update({'tree_method': 'gpu_hist'})\n",
    "alpha_logger.info(\"params before: {}\".format(xgb_conf.params))\n",
    "tic = time.time()\n",
    "\n",
    "# hyper_parameters optimization\n",
    "# opt_parameters = {'max_depth': (2, 12),\n",
    "#                   'gamma': (0.001, 10.0),\n",
    "#                   'min_child_weight': (0, 20),\n",
    "#                   'max_delta_step': (0, 10),\n",
    "#                   'subsample': (0.01, 0.99),\n",
    "#                   'colsample_bytree': (0.01, 0.99)\n",
    "#                  }\n",
    "\n",
    "# opt_xgb = BayesOptimizationXGB('regression', x_train, y_train)\n",
    "# params_op = opt_xgb.train_opt(opt_parameters)\n",
    "# xgb_conf.params.update(params_op)\n",
    "alpha_logger.info(\"params after: {}\".format(xgb_conf.params))\n",
    "alpha_logger.info(\"hyper params optimize time : {}\".format(time.time() - tic))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model training\n",
    "xgb_model = XGBooster(xgb_conf)\n",
    "alpha_logger.info('xgb_model params: \\n{0}'.format(xgb_model.get_params()))\n",
    "\n",
    "best_score, best_round, best_model = xgb_model.fit(x_train, y_train)\n",
    "alpha_logger.info('Training time cost {}s'.format(time.time() - tic))\n",
    "alpha_logger.info('best_score = {}, best_round = {}'.format(best_score, best_round))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 当天数据预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 取调仓日当天的因子数据作为输入.\n",
    "# total_data_test_excess = train_data[train_data.trade_date == str(ref_date)]\n",
    "total_data_test_excess = factor_data[factor_data.trade_date == ref_date]\n",
    "\n",
    "if len(total_data_test_excess) <=0:\n",
    "    alpha_logger.info('{} HAS NO DATA!!!'.format(ref_date))\n",
    "    sys.exit()\n",
    "\n",
    "alpha_logger.info('{0} total_data_test_excess: {1}'.format(ref_date, len(total_data_test_excess)))\n",
    "\n",
    "# 获取调仓日当天的行业, 风险模型和基准权重数据\n",
    "industry_matrix = industry_total[industry_total.trade_date == ref_date]\n",
    "benchmark_weight = benchmark_total[benchmark_total.trade_date == ref_date]\n",
    "risk_matrix = risk_total[risk_total.trade_date == ref_date]\n",
    "\n",
    "total_data = pd.merge(industry_matrix, benchmark_weight, on=['code'], how='left').fillna(0.)\n",
    "total_data = pd.merge(total_data, risk_matrix, on=['code'])\n",
    "alpha_logger.info('{0} type_of_total_data: {1}'.format(ref_date, type(total_data)))\n",
    "alpha_logger.info('{0} shape_of_total_data: {1}'.format(ref_date, np.shape(total_data)))\n",
    "    \n",
    "total_data_test_excess = pd.merge(total_data, total_data_test_excess, on=['code'])\n",
    "alpha_logger.info('{0} len_of_total_data_test_excess: {1}'.format(ref_date, len(total_data_test_excess)))\n",
    "\n",
    "# 股票代码\n",
    "codes = total_data_test_excess.code.values.tolist()\n",
    "   \n",
    "# predict\n",
    "# alpha_logger.info('total_data_test_excess: \\n{}'.format(total_data_test_excess[['weight', 'code', 'industry']]))\n",
    "x_pred = total_data_test_excess[features]\n",
    "predict_xgboost = xgb_model.predict(best_model, x_pred)\n",
    "# alpha_logger.info('predict_xgboost: {}'.format(predict_xgboost))\n",
    "\n",
    "a = np.shape(predict_xgboost)\n",
    "predict_xgboost = np.reshape(predict_xgboost, (a[0], -1)).astype(np.float64)\n",
    "alpha_logger.info('shape_of_predict_xgboost: {}'.format(np.shape(predict_xgboost)))\n",
    "\n",
    "# 收益率预测结果    \n",
    "predict_xgboost_df = pd.DataFrame({'xgb_pre': list(predict_xgboost.reshape(-1))})\n",
    "predict_xgboost_df['trade_date'] = ref_date\n",
    "predict_xgboost_df['code'] = codes\n",
    "predict_xgboost_df['code'] = predict_xgboost_df['code'].apply(lambda x: \"{:06d}\".format(x) + '.XSHG'\n",
    "                                                              if len(str(x))==6 and str(x)[0] in '6' \n",
    "                                                              else \"{:06d}\".format(x) + '.XSHE')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 获取昨持仓信息"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from data.engines.sqlengine import SQLEngine\n",
    "\n",
    "# 获取当前持仓\n",
    "record_engine = SQLEngine('sqlite:///./{}/real_tune_record_without_alpha.db'.format(weekly))\n",
    "\n",
    "try:\n",
    "    # Method 1\n",
    "    pos_record = record_engine.fetch_record('pos_record')\n",
    "    previous_pos = pos_record[pos_record['trade_date'] == adjusted_date_pre]\n",
    "    # Method 2\n",
    "    # previous_pos = record_engine.fetch_record_meta(Record, adjusted_date_pre)\n",
    "    \n",
    "except Exception as e:\n",
    "    alpha_logger.info('pos_record Exception:{0}'.format(e))\n",
    "    previous_pos = pd.DataFrame({'trade_date':[], 'weight':[],'industry':[], 'er':[],'code':[]})\n",
    "\n",
    "alpha_logger.info('previous_pos_data: {0}, pos_len: {1}'.format(adjusted_date_pre, len(previous_pos)))\n",
    "\n",
    "# 股票过滤, 组合优化之前过滤掉(未完成)\n",
    "## 9:00--9:25之间进行涨跌停股票的实时筛选\n",
    "\n",
    "# 导入昨持仓并与股票池中所有股票合并, \n",
    "if len(previous_pos) <= 0:\n",
    "    previous_position = None\n",
    "else:\n",
    "    previous_pos = total_data_test_excess[['code']].merge(previous_pos, on=['code'], how='left',).fillna(0)\n",
    "    previous_position = previous_pos.weight.values\n",
    "# alpha_logger.info('previous_position:\\n {}'.format(previous_position))\n",
    "\n",
    "# previous_pos = total_data_test_excess[['code']].merge(previous_pos, on=['code'], how='left').fillna(0)\n",
    "# previous_position = previous_pos.weight.values\n",
    "\n",
    "# print(previous_position.shape)\n",
    "# print(total_data_test_excess.shape)\n",
    "# print(previous_position.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 组合优化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Constraintes settings\n",
    "industry_names = industry_list(industry_name, industry_level)\n",
    "constraint_risk = ['EARNYILD', 'LIQUIDTY', 'GROWTH', 'SIZE', 'SIZENL', 'BETA', 'MOMENTUM'] + industry_names\n",
    "\n",
    "total_risk_names = constraint_risk + ['benchmark', 'total']\n",
    "\n",
    "b_type = []\n",
    "l_val = []\n",
    "u_val = []\n",
    "\n",
    "for name in total_risk_names:\n",
    "    if name == 'benchmark':\n",
    "        b_type.append(BoundaryType.RELATIVE)\n",
    "        l_val.append(0.0)\n",
    "        u_val.append(1.0)\n",
    "    elif name == 'total':\n",
    "        b_type.append(BoundaryType.ABSOLUTE)\n",
    "        l_val.append(-0.0)\n",
    "        u_val.append(0.0)\n",
    "    elif name == 'SIZE':\n",
    "        b_type.append(BoundaryType.ABSOLUTE)\n",
    "        l_val.append(-1.0)\n",
    "        u_val.append(1.0)\n",
    "    elif name == 'SIZENL':\n",
    "        b_type.append(BoundaryType.ABSOLUTE)\n",
    "        l_val.append(-1.0)\n",
    "        u_val.append(1.0)\n",
    "    elif name in industry_names:\n",
    "        b_type.append(BoundaryType.ABSOLUTE)\n",
    "        l_val.append(-0.005)\n",
    "        u_val.append(0.005)\n",
    "    else:\n",
    "        b_type.append(BoundaryType.ABSOLUTE)\n",
    "        l_val.append(-2.0)\n",
    "        u_val.append(2.0)\n",
    "bounds = create_box_bounds(total_risk_names, b_type, l_val, u_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark_w = total_data_test_excess.weight.values\n",
    "alpha_logger.info('type_of_benchmark_w: {}, shape_of_benchmark_w: {}'.format(type(benchmark_w), \n",
    "                                                                             np.shape(benchmark_w)))\n",
    "is_in_benchmark = (benchmark_w > 0.).astype(float).reshape((-1, 1))\n",
    "\n",
    "# 风险模型数据合并\n",
    "# weight_gap = 0.02\n",
    "# turn_over_rate = 0.2\n",
    "total_risk_exp = np.concatenate([total_data_test_excess[constraint_risk].values.astype(float),\n",
    "                                 is_in_benchmark,\n",
    "                                 np.ones_like(is_in_benchmark)],\n",
    "                                axis=1)\n",
    "\n",
    "alpha_logger.info('shape_of_total_risk_exp_pre: {}'.format(np.shape(total_risk_exp)))\n",
    "total_risk_exp = pd.DataFrame(total_risk_exp, columns=total_risk_names)\n",
    "alpha_logger.info('shape_of_total_risk_exp: {}'.format(np.shape(total_risk_exp)))\n",
    "\n",
    "constraints = LinearConstraints(bounds, total_risk_exp, benchmark_w)\n",
    "alpha_logger.info('constraints: {0} in {1}'.format(np.shape(constraints.risk_targets()), ref_date))\n",
    "\n",
    "lbound = np.maximum(0., benchmark_w - weight_gap)\n",
    "ubound = weight_gap + benchmark_w\n",
    "alpha_logger.info('lbound: {0} in {1}'.format(np.shape(lbound), ref_date))\n",
    "alpha_logger.info('ubound: {0} in {1}'.format(np.shape(ubound), ref_date))\n",
    "\n",
    "# 组合优化\n",
    "executor = NaiveExecutor()\n",
    "current_pos = pd.DataFrame()\n",
    "\n",
    "target_pos, _ = er_portfolio_analysis(predict_xgboost, \n",
    "                                      total_data_test_excess['industry'].values,\n",
    "                                      None,\n",
    "                                      constraints,\n",
    "                                      False,\n",
    "                                      benchmark_w,\n",
    "                                      method='risk_neutral',\n",
    "                                      lbound=lbound,\n",
    "                                      ubound=ubound,\n",
    "                                      turn_over_target=turn_over_rate,\n",
    "                                      current_position=previous_position)\n",
    "                  \n",
    "alpha_logger.info('shape_of_target_pos: {}'.format(np.shape(target_pos)))\n",
    "alpha_logger.info('len_codes:{}'.format(np.shape(codes)))\n",
    "target_pos['code'] = codes\n",
    "# alpha_logger.info('target_pos: \\n{}'.format(target_pos))\n",
    "\n",
    "# 换手率计算\n",
    "executor.set_current(previous_pos)\n",
    "turn_over_org, current_pos = executor.execute(target_pos=target_pos)\n",
    "alpha_logger.info('turn_over_org: {}'.format(turn_over_org))\n",
    "turn_over = turn_over_org / sum(target_pos.weight.values)\n",
    "alpha_logger.info('turn_over: {}'.format(turn_over))\n",
    "\n",
    "# 优化后仓位信息\n",
    "## 调仓日\n",
    "current_pos['adjust_date'] = ref_date\n",
    "## 交易日\n",
    "current_pos['trade_date'] = adjusted_date\n",
    "alpha_logger.info('{} is finished'.format(adjusted_date))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## 修改code格式\n",
    "## 取TOP N作为真实的下单股票\n",
    "real_pos = current_pos.sort_values(by='weight', ascending=False)[:50]\n",
    "real_pos['weight'] = real_pos['weight'] / real_pos['weight'].sum()\n",
    "real_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 保存记录当前持仓信息, 写入数据库\n",
    "## 字段说明:{weight: 持股权重, industry:所属行业, er:收益率, code:股票代码, adjust_date:调仓日, trade_date:交易日}\n",
    "## 注, adjust_date表示模型运行所需要的数据截止日, trade_date表示策略下单交易的日期\n",
    "previous_record = record_engine.fetch_record_meta(Record, adjusted_date)\n",
    "if len(previous_record) == 0:\n",
    "    record_engine.write_data('pos_record', real_pos)\n",
    "else:\n",
    "    record_engine.del_historical_data(Record, adjusted_date)  # 删除同日期的历史数据\n",
    "    tmp_record = record_engine.fetch_record_meta(Record, adjusted_date)\n",
    "    if len(tmp_record) == 0:  # 删除成功\n",
    "        record_engine.write_data('pos_record', real_pos)\n",
    "    else:\n",
    "        print('{} 的数据没有删除: {}'.format(adjusted_date, len(previous_record)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## 生成交易记录\n",
    "## 修改code格式\n",
    "real_pos['code'] = real_pos['code'].apply(lambda x: \"{:06d}\".format(x) + '.SH' \n",
    "                                          if len(str(x))==6 and str(x)[0] in '6' \n",
    "                                          else \"{:06d}\".format(x) + '.SZ')\n",
    "\n",
    "real_pos = real_pos.loc[:, ['code', 'weight', 'trade_date']]\n",
    "# real_pos = real_pos.loc[:, ['code', 'weight']]\n",
    "# real_pos['trade_date'] = adjust_date\n",
    "\n",
    "real_pos.rename(columns={\"code\": \"证券代码\", \"weight\": \"持仓权重\", \"trade_date\": \"成分日期\"}, inplace=True)\n",
    "real_pos['交易价格'] = 0\n",
    "\n",
    "real_pos = real_pos[['证券代码', '持仓权重', '交易价格', '成分日期']].copy()\n",
    "real_pos.to_csv('./{}/base_{}.csv'.format(weekly, str(adjusted_date.date())), encoding='utf_8_sig', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 查看持仓记录\n",
    "previous_record = record_engine.fetch_record_meta(Record, adjusted_date)\n",
    "# previous_record = record_engine.fetch_record('pos_record')\n",
    "# previous_record = current_record[current_record['trade_date'] == adjusted_date]\n",
    "previous_record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "str(adjusted_date.date())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
