{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 基础因子实时计算"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "zz500模拟盘操作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "sys.path.append('../../')\n",
    "sys.path.append('../../../')\n",
    "sys.path.append('../../../../')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from PyFin.api import *\n",
    "from alphamind.api import *\n",
    "from conf.models import *\n",
    "from conf.config import*\n",
    "from data.engines.model import Record\n",
    "from alphamind.execution.naiveexecutor import NaiveExecutor\n",
    "from stacking import factor_store, feature_list\n",
    "from optimization.bayes_optimization_xgb import *\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('max_colwidth',100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 因子数据准备"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 指定需要执行的日期和保存的文件夹\n",
    "# start_date = '2010-01-19'  # 训练集的起始时间\n",
    "start_date = '2019-10-24'  # 训练集的起始时间\n",
    "end_date = '2020-01-10'\n",
    "# 设置保存的文件目录\n",
    "weekly = 's_1'  # {s1: 周一, s2: 周二,  s3: 周三, s4: 周四, s5: 周五}\n",
    "\n",
    "# 优化器参数设定\n",
    "weight_gap = 0.02\n",
    "turn_over_rate = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "code_folding": [],
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[datetime.datetime(2019, 10, 24, 0, 0),\n",
       " datetime.datetime(2019, 10, 25, 0, 0),\n",
       " datetime.datetime(2019, 10, 28, 0, 0),\n",
       " datetime.datetime(2019, 10, 29, 0, 0),\n",
       " datetime.datetime(2019, 10, 30, 0, 0),\n",
       " datetime.datetime(2019, 10, 31, 0, 0),\n",
       " datetime.datetime(2019, 11, 1, 0, 0),\n",
       " datetime.datetime(2019, 11, 4, 0, 0),\n",
       " datetime.datetime(2019, 11, 5, 0, 0),\n",
       " datetime.datetime(2019, 11, 6, 0, 0),\n",
       " datetime.datetime(2019, 11, 7, 0, 0),\n",
       " datetime.datetime(2019, 11, 8, 0, 0),\n",
       " datetime.datetime(2019, 11, 11, 0, 0),\n",
       " datetime.datetime(2019, 11, 12, 0, 0),\n",
       " datetime.datetime(2019, 11, 13, 0, 0),\n",
       " datetime.datetime(2019, 11, 14, 0, 0),\n",
       " datetime.datetime(2019, 11, 15, 0, 0),\n",
       " datetime.datetime(2019, 11, 18, 0, 0),\n",
       " datetime.datetime(2019, 11, 19, 0, 0),\n",
       " datetime.datetime(2019, 11, 20, 0, 0),\n",
       " datetime.datetime(2019, 11, 21, 0, 0),\n",
       " datetime.datetime(2019, 11, 22, 0, 0),\n",
       " datetime.datetime(2019, 11, 25, 0, 0),\n",
       " datetime.datetime(2019, 11, 26, 0, 0),\n",
       " datetime.datetime(2019, 11, 27, 0, 0),\n",
       " datetime.datetime(2019, 11, 28, 0, 0),\n",
       " datetime.datetime(2019, 11, 29, 0, 0),\n",
       " datetime.datetime(2019, 12, 2, 0, 0),\n",
       " datetime.datetime(2019, 12, 3, 0, 0),\n",
       " datetime.datetime(2019, 12, 4, 0, 0),\n",
       " datetime.datetime(2019, 12, 5, 0, 0),\n",
       " datetime.datetime(2019, 12, 6, 0, 0),\n",
       " datetime.datetime(2019, 12, 9, 0, 0),\n",
       " datetime.datetime(2019, 12, 10, 0, 0),\n",
       " datetime.datetime(2019, 12, 11, 0, 0),\n",
       " datetime.datetime(2019, 12, 12, 0, 0),\n",
       " datetime.datetime(2019, 12, 13, 0, 0),\n",
       " datetime.datetime(2019, 12, 16, 0, 0),\n",
       " datetime.datetime(2019, 12, 17, 0, 0),\n",
       " datetime.datetime(2019, 12, 18, 0, 0),\n",
       " datetime.datetime(2019, 12, 19, 0, 0),\n",
       " datetime.datetime(2019, 12, 20, 0, 0),\n",
       " datetime.datetime(2019, 12, 23, 0, 0),\n",
       " datetime.datetime(2019, 12, 24, 0, 0),\n",
       " datetime.datetime(2019, 12, 25, 0, 0),\n",
       " datetime.datetime(2019, 12, 26, 0, 0),\n",
       " datetime.datetime(2019, 12, 27, 0, 0),\n",
       " datetime.datetime(2019, 12, 30, 0, 0),\n",
       " datetime.datetime(2019, 12, 31, 0, 0),\n",
       " datetime.datetime(2020, 1, 1, 0, 0),\n",
       " datetime.datetime(2020, 1, 2, 0, 0),\n",
       " datetime.datetime(2020, 1, 3, 0, 0),\n",
       " datetime.datetime(2020, 1, 6, 0, 0),\n",
       " datetime.datetime(2020, 1, 7, 0, 0),\n",
       " datetime.datetime(2020, 1, 8, 0, 0),\n",
       " datetime.datetime(2020, 1, 9, 0, 0),\n",
       " datetime.datetime(2020, 1, 10, 0, 0)]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "universe = Universe('zz500')\n",
    "freq = '1b'\n",
    "benchmark_code = 905\n",
    "ref_dates = makeSchedule(start_date, end_date, freq, 'china.sse')\n",
    "# ref_dates = ref_dates.pop(ref_dates[-2])\n",
    "horizon = map_freq(freq)\n",
    "industry_name = 'sw'\n",
    "industry_level = 1\n",
    "\n",
    "# 前一个调仓日, 用于获取前一个调仓日的持仓信息\n",
    "ref_date_pre = ref_dates[-2]\n",
    "# 当前调仓日\n",
    "ref_date = ref_dates[-1]\n",
    "\n",
    "# 因子数据库\n",
    "data_source = alpha_db\n",
    "engine = SqlEngine(data_source)\n",
    "ref_dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# uqer因子列表\n",
    "basic_factor_store = factor_store.basic_factor_store\n",
    "# alpha191因子列表\n",
    "alpha_factor_store = factor_store.alpha_factor_store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# 提取Uqer因子\n",
    "basic_factor_org = engine.fetch_factor_range(universe, basic_factor_store, dates=ref_dates)\n",
    "# 提取alpha191因子\n",
    "# alpha191_factor_org = engine.fetch_factor_range(universe, \n",
    "#                                                 alpha_factor_store, \n",
    "#                                                 dates=ref_dates, \n",
    "#                                                 used_factor_tables=[Alpha191]).drop(['chgPct','secShortName'], axis=1)\n",
    "# # 合并所有的因子\n",
    "# factor_data_org = pd.merge(basic_factor_org, alpha191_factor_org, on=['trade_date', 'code'], how='outer')\n",
    "factor_data_org = basic_factor_org\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(set(factor_data_org['trade_date']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# assert len(set(factor_data_org['trade_date'])) == len(ref_dates)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot factor value over time on code\n",
    "from matplotlib import pyplot as plt\n",
    "from pylab import rcParams\n",
    "rcParams['figure.figsize'] = 10, 2 # width 10, height 8\n",
    "\n",
    "ax = factor_data_org[factor_data_org['code'] == 6].plot(x='trade_date', y='ACCA', style='b-', grid=True)\n",
    "ax.set_xlabel(\"date\")\n",
    "ax.set_ylabel(\"ACCA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 因子预处理\n",
    "## 确失值填充\n",
    "factor_mean = factor_data_org.mean()\n",
    "factor_std = factor_data_org.std()\n",
    "factor_data_org = factor_data_org.fillna(factor_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# 获取所属行业\n",
    "industry = engine.fetch_industry_range(universe, dates=ref_dates)\n",
    "# factor_data = pd.merge(factor_data_org, industry, on=['trade_date', 'code']).fillna(0.)\n",
    "factor_data = pd.merge(factor_data_org, industry, on=['trade_date', 'code'])\n",
    "\n",
    "# 获取风险因子\n",
    "risk_total = engine.fetch_risk_model_range(universe, dates=ref_dates)[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "return_data = engine.fetch_dx_return_range(universe, dates=ref_dates, horizon=horizon, offset=0,benchmark = benchmark_code)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "return_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "benchmark_total = engine.fetch_benchmark_range(dates=ref_dates, benchmark=benchmark_code)\n",
    "industry_total = engine.fetch_industry_matrix_range(universe, dates=ref_dates, category=industry_name, level=industry_level)\n",
    "\n",
    "train_data = pd.merge(factor_data, return_data, on=['trade_date', 'code']).dropna()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot adjusted close over time on code\n",
    "from matplotlib import pyplot as plt\n",
    "from pylab import rcParams\n",
    "rcParams['figure.figsize'] = 10, 2 # width 10, height 8\n",
    "\n",
    "ax = train_data[train_data['code'] == 6].plot(x='trade_date', y='dx', style='b-', grid=True)\n",
    "ax.set_xlabel(\"date\")\n",
    "ax.set_ylabel(\"dx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 获取特征名\n",
    "features = list(basic_factor_store.keys())\n",
    "alpha_features = list(alpha_factor_store.keys())\n",
    "# features = feature_list.uqer_features\n",
    "# alpha_features = feature_list.alpha_features\n",
    "# features.extend(alpha_features)\n",
    "\n",
    "label = ['dx']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "from models.m1_xgb import *\n",
    "from conf.configuration import xgb_conf\n",
    "from data.engines.model import Record\n",
    "import xgboost as xgb\n",
    "import gc\n",
    "\n",
    "alpha_logger.info('{0} is start'.format(ref_date))\n",
    "\n",
    "# machine learning model\n",
    "## Filter Training data\n",
    "## 训练集构造\n",
    "trade_date_pre = ref_date - timedelta(days=1)\n",
    "# trade_date_pre_80 = ref_date - timedelta(days=80)\n",
    "\n",
    "## 1、选择调仓日当天之前(不含当天)并且在80天以内的因子数据作为训练集.\n",
    "# train = train_data[(train_data.trade_date <= trade_date_pre) & (trade_date_pre_80 <= train_data.trade_date)].dropna()\n",
    "## 2、选择调仓日当天之前(不含当天)的因子数据作为训练集.\n",
    "train = train_data[train_data.trade_date <= trade_date_pre].dropna()\n",
    "alpha_logger.info('trade_date_pre {0}'.format(trade_date_pre))\n",
    "\n",
    "if len(train) <= 0:\n",
    "    alpha_logger.info('{0} HAS NO TRAIN DATA!!!'.format(ref_date))\n",
    "\n",
    "x_train = train[features]\n",
    "y_train = train[label]\n",
    "alpha_logger.info('len_x_train: {0}, len_y_train: {1}'.format(len(x_train.values), len(y_train.values)))\n",
    "alpha_logger.info('X_train.shape={0}, X_test.shape = {1}'.format(np.shape(x_train), np.shape(y_train)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 超参寻优"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load xgboost regression configuration\n",
    "xgb_conf.xgb_config_r()\n",
    "xgb_conf.cv_folds = None\n",
    "xgb_conf.early_stop_round = 100\n",
    "xgb_conf.max_round = 800\n",
    "xgb_conf.params.update({'nthread': 12})\n",
    "\n",
    "GPU_device = False\n",
    "if GPU_device:\n",
    "    # use GPUs\n",
    "    xgb_conf.params.update({'tree_method': 'gpu_hist'})\n",
    "alpha_logger.info(\"params before: {}\".format(xgb_conf.params))\n",
    "tic = time.time()\n",
    "\n",
    "# hyper_parameters optimization\n",
    "# opt_parameters = {'max_depth': (2, 12),\n",
    "#                   'gamma': (0.001, 10.0),\n",
    "#                   'min_child_weight': (0, 20),\n",
    "#                   'max_delta_step': (0, 10),\n",
    "#                   'subsample': (0.01, 0.99),\n",
    "#                   'colsample_bytree': (0.01, 0.99)\n",
    "#                  }\n",
    "\n",
    "# opt_xgb = BayesOptimizationXGB('regression', x_train, y_train)\n",
    "# params_op = opt_xgb.train_opt(opt_parameters)\n",
    "# xgb_conf.params.update(params_op)\n",
    "alpha_logger.info(\"params after: {}\".format(xgb_conf.params))\n",
    "alpha_logger.info(\"hyper params optimize time : {}\".format(time.time() - tic))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model training\n",
    "xgb_model = XGBooster(xgb_conf)\n",
    "alpha_logger.info('xgb_model params: \\n{0}'.format(xgb_model.get_params()))\n",
    "\n",
    "best_score, best_round, best_model = xgb_model.fit(x_train, y_train)\n",
    "alpha_logger.info('Training time cost {}s'.format(time.time() - tic))\n",
    "alpha_logger.info('best_score = {}, best_round = {}'.format(best_score, best_round))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 当天数据预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 取调仓日当天的因子数据作为输入.\n",
    "# total_data_test_excess = train_data[train_data.trade_date == str(ref_date)]\n",
    "total_data_test_excess = factor_data[factor_data.trade_date == ref_date]\n",
    "\n",
    "if len(total_data_test_excess) <=0:\n",
    "    alpha_logger.info('{} HAS NO DATA!!!'.format(ref_date))\n",
    "    sys.exit()\n",
    "\n",
    "alpha_logger.info('{0} total_data_test_excess: {1}'.format(ref_date, len(total_data_test_excess)))\n",
    "\n",
    "# 获取调仓日当天的行业, 风险模型和基准权重数据\n",
    "industry_matrix = industry_total[industry_total.trade_date == ref_date]\n",
    "benchmark_weight = benchmark_total[benchmark_total.trade_date == ref_date]\n",
    "risk_matrix = risk_total[risk_total.trade_date == ref_date]\n",
    "\n",
    "total_data = pd.merge(industry_matrix, benchmark_weight, on=['code'], how='left').fillna(0.)\n",
    "total_data = pd.merge(total_data, risk_matrix, on=['code'])\n",
    "alpha_logger.info('{0} type_of_total_data: {1}'.format(ref_date, type(total_data)))\n",
    "alpha_logger.info('{0} shape_of_total_data: {1}'.format(ref_date, np.shape(total_data)))\n",
    "    \n",
    "total_data_test_excess = pd.merge(total_data, total_data_test_excess, on=['code'])\n",
    "alpha_logger.info('{0} len_of_total_data_test_excess: {1}'.format(ref_date, len(total_data_test_excess)))\n",
    "\n",
    "# 股票代码\n",
    "codes = total_data_test_excess.code.values.tolist()\n",
    "   \n",
    "# predict\n",
    "# alpha_logger.info('total_data_test_excess: \\n{}'.format(total_data_test_excess[['weight', 'code', 'industry']]))\n",
    "x_pred = total_data_test_excess[features]\n",
    "predict_xgboost = xgb_model.predict(best_model, x_pred)\n",
    "# alpha_logger.info('predict_xgboost: {}'.format(predict_xgboost))\n",
    "\n",
    "a = np.shape(predict_xgboost)\n",
    "predict_xgboost = np.reshape(predict_xgboost, (a[0], -1)).astype(np.float64)\n",
    "alpha_logger.info('shape_of_predict_xgboost: {}'.format(np.shape(predict_xgboost)))\n",
    "\n",
    "# 收益率预测结果    \n",
    "predict_xgboost_df = pd.DataFrame({'xgb_pre': list(predict_xgboost.reshape(-1))})\n",
    "predict_xgboost_df['trade_date'] = ref_date\n",
    "predict_xgboost_df['code'] = codes\n",
    "predict_xgboost_df['code'] = predict_xgboost_df['code'].apply(lambda x: \"{:06d}\".format(x) + '.XSHG'\n",
    "                                                              if len(str(x))==6 and str(x)[0] in '6' \n",
    "                                                              else \"{:06d}\".format(x) + '.XSHE')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 获取昨持仓信息"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data.engines.sqlengine import SQLEngine\n",
    "\n",
    "# 获取当前持仓\n",
    "record_engine = SQLEngine('sqlite:///./{}/real_tune_record_without_alpha.db'.format(weekly))\n",
    "\n",
    "try:\n",
    "#     pos_record = record_engine.fetch_record('pos_record')\n",
    "#     previous_pos = pos_record[pos_record['trade_date'] == ref_date_pre]\n",
    "    previous_pos = record_engine.fetch_record_meta(Record, ref_date_pre)\n",
    "    \n",
    "except Exception as e:\n",
    "    alpha_logger.info('pos_record Exception:{0}'.format(e))\n",
    "    previous_pos = pd.DataFrame({'trade_date':[], 'weight':[],'industry':[], 'er':[],'code':[]})\n",
    "\n",
    "alpha_logger.info('previous_pos_data: {0}, pos_len: {1}'.format(ref_date_pre, len(previous_pos)))\n",
    "\n",
    "# 股票过滤, 组合优化之前过滤掉(未完成)\n",
    "## 9:00--9:25之间进行涨跌停股票的实时筛选\n",
    "\n",
    "# 导入昨持仓并与股票池中所有股票合并, \n",
    "if len(previous_pos) <= 0:\n",
    "    current_position = None\n",
    "else:\n",
    "    previous_pos = total_data_test_excess[['code']].merge(previous_pos, on=['code'], how='left',).fillna(0)\n",
    "    current_position = previous_pos.weight.values\n",
    "alpha_logger.info('previous_pos:\\n {}'.format(previous_pos))\n",
    "\n",
    "# previous_pos = total_data_test_excess[['code']].merge(previous_pos, on=['code'], how='left').fillna(0)\n",
    "# current_position = previous_pos.weight.values\n",
    "\n",
    "# print(current_position.shape)\n",
    "# print(total_data_test_excess.shape)\n",
    "# print(previous_pos.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 组合优化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Constraintes settings\n",
    "industry_names = industry_list(industry_name, industry_level)\n",
    "constraint_risk = ['EARNYILD', 'LIQUIDTY', 'GROWTH', 'SIZE', 'SIZENL', 'BETA', 'MOMENTUM'] + industry_names\n",
    "\n",
    "total_risk_names = constraint_risk + ['benchmark', 'total']\n",
    "\n",
    "b_type = []\n",
    "l_val = []\n",
    "u_val = []\n",
    "\n",
    "for name in total_risk_names:\n",
    "    if name == 'benchmark':\n",
    "        b_type.append(BoundaryType.RELATIVE)\n",
    "        l_val.append(0.0)\n",
    "        u_val.append(1.0)\n",
    "    elif name == 'total':\n",
    "        b_type.append(BoundaryType.ABSOLUTE)\n",
    "        l_val.append(-0.0)\n",
    "        u_val.append(0.0)\n",
    "    elif name == 'SIZE':\n",
    "        b_type.append(BoundaryType.ABSOLUTE)\n",
    "        l_val.append(-1.0)\n",
    "        u_val.append(1.0)\n",
    "    elif name == 'SIZENL':\n",
    "        b_type.append(BoundaryType.ABSOLUTE)\n",
    "        l_val.append(-1.0)\n",
    "        u_val.append(1.0)\n",
    "    elif name in industry_names:\n",
    "        b_type.append(BoundaryType.ABSOLUTE)\n",
    "        l_val.append(-0.005)\n",
    "        u_val.append(0.005)\n",
    "    else:\n",
    "        b_type.append(BoundaryType.ABSOLUTE)\n",
    "        l_val.append(-2.0)\n",
    "        u_val.append(2.0)\n",
    "bounds = create_box_bounds(total_risk_names, b_type, l_val, u_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark_w = total_data_test_excess.weight.values\n",
    "alpha_logger.info('type_of_benchmark_w: {}, shape_of_benchmark_w: {}'.format(type(benchmark_w), \n",
    "                                                                             np.shape(benchmark_w)))\n",
    "is_in_benchmark = (benchmark_w > 0.).astype(float).reshape((-1, 1))\n",
    "\n",
    "# 风险模型数据合并\n",
    "## 组合优化参数\n",
    "# weight_gap = 0.02\n",
    "# turn_over_rate = 0.1\n",
    "total_risk_exp = np.concatenate([total_data_test_excess[constraint_risk].values.astype(float),\n",
    "                                 is_in_benchmark,\n",
    "                                 np.ones_like(is_in_benchmark)],\n",
    "                                axis=1)\n",
    "\n",
    "alpha_logger.info('shape_of_total_risk_exp_pre: {}'.format(np.shape(total_risk_exp)))\n",
    "total_risk_exp = pd.DataFrame(total_risk_exp, columns=total_risk_names)\n",
    "alpha_logger.info('shape_of_total_risk_exp: {}'.format(np.shape(total_risk_exp)))\n",
    "\n",
    "constraints = LinearConstraints(bounds, total_risk_exp, benchmark_w)\n",
    "alpha_logger.info('constraints: {0} in {1}'.format(np.shape(constraints.risk_targets()), ref_date))\n",
    "\n",
    "lbound = np.maximum(0., benchmark_w - weight_gap)\n",
    "ubound = weight_gap + benchmark_w\n",
    "alpha_logger.info('lbound: {0} in {1}'.format(np.shape(lbound), ref_date))\n",
    "alpha_logger.info('ubound: {0} in {1}'.format(np.shape(ubound), ref_date))\n",
    "\n",
    "# 组合优化\n",
    "executor = NaiveExecutor()\n",
    "current_pos = pd.DataFrame()\n",
    "\n",
    "target_pos, _ = er_portfolio_analysis(predict_xgboost, \n",
    "                                      total_data_test_excess['industry'].values,\n",
    "                                      None,\n",
    "                                      constraints,\n",
    "                                      False,\n",
    "                                      benchmark_w,\n",
    "                                      method='risk_neutral',\n",
    "                                      lbound=lbound,\n",
    "                                      ubound=ubound,\n",
    "                                      turn_over_target=turn_over_rate,\n",
    "                                      current_position=current_position)\n",
    "                  \n",
    "alpha_logger.info('shape_of_target_pos: {}'.format(np.shape(target_pos)))\n",
    "alpha_logger.info('len_codes:{}'.format(np.shape(codes)))\n",
    "target_pos['code'] = codes\n",
    "# alpha_logger.info('target_pos: \\n{}'.format(target_pos))\n",
    "\n",
    "# 换手率计算\n",
    "executor.set_current(previous_pos)\n",
    "turn_over_org, current_pos = executor.execute(target_pos=target_pos)\n",
    "alpha_logger.info('turn_over_org: {}'.format(turn_over_org))\n",
    "turn_over = turn_over_org / sum(target_pos.weight.values)\n",
    "alpha_logger.info('turn_over: {}'.format(turn_over))\n",
    "\n",
    "# 优化后仓位信息\n",
    "current_pos['trade_date'] = ref_date\n",
    "alpha_logger.info('{} is finished'.format(ref_date))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## 修改code格式\n",
    "## 取TOP N作为真实的下单股票\n",
    "real_pos = current_pos.sort_values(by='weight', ascending=False)[:50]\n",
    "real_pos['weight'] = real_pos['weight'] / real_pos['weight'].sum()\n",
    "real_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 保存记录当前持仓信息, 写入数据库\n",
    "previous_record = record_engine.fetch_record_meta(Record, ref_date)\n",
    "if len(previous_record) == 0:\n",
    "    record_engine.write_data('pos_record', real_pos)\n",
    "else:\n",
    "    record_engine.del_historical_data(Record, ref_date)  # 删除同日期的历史数据\n",
    "    tmp_record = record_engine.fetch_record_meta(Record, ref_date)\n",
    "    if len(tmp_record) == 0:  # 删除成功\n",
    "        record_engine.write_data('pos_record', real_pos)\n",
    "    else:\n",
    "        print('{} 的数据没有删除: {}'.format(ref_date, len(previous_record)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# 生成交易记录\n",
    "## 修改code格式\n",
    "real_pos['code'] = real_pos['code'].apply(lambda x: \"{:06d}\".format(x) + '.SH' \n",
    "                                          if len(str(x))==6 and str(x)[0] in '6' \n",
    "                                          else \"{:06d}\".format(x) + '.SZ')\n",
    "\n",
    "real_pos = real_pos.loc[:, ['code', 'weight', 'trade_date']]\n",
    "real_pos.rename(columns={\"code\": \"证券代码\", \"weight\": \"持仓权重\", \"trade_date\": \"成分日期\"}, inplace=True)\n",
    "real_pos['交易价格'] = 0\n",
    "\n",
    "real_pos = real_pos[['证券代码', '持仓权重', '交易价格', '成分日期']].copy()\n",
    "real_pos.to_csv('./{}/every_day_{}.csv'.format(weekly, end_date), encoding='utf_8_sig', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 查看持仓记录\n",
    "current_record = record_engine.fetch_record_meta(Record, ref_date)\n",
    "# current_record = current_record[current_record['trade_date'] == ref_date]\n",
    "current_record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_record['trade_date'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
